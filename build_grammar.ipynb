{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pyts.approximation import SymbolicAggregateApproximation\n",
    "import numpy as np\n",
    "from sksequitur import Grammar, Parser, Production, Mark\n",
    "import nltk\n",
    "from nltk import CFG\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate grammar from sequitus algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_items = pd.read_csv('frequent_items.csv')\n",
    "frequent_items = frequent_items[frequent_items['count'] > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48516"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frequent_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = Parser()\n",
    "for item in frequent_items['item']:\n",
    "    parser.feed([Mark()])\n",
    "    parser.feed(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = Grammar(parser.tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_adjacent_letters(input_string):\n",
    "    # Define a regular expression pattern to match two or more adjacent letters\n",
    "    pattern = re.compile(r'([a-z])\\1')\n",
    "\n",
    "    # Use the sub() function to replace matched patterns with an empty string\n",
    "    result = re.sub(pattern, '', input_string)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('grammar_start.txt', 'w') as f:\n",
    "    print(grammar, file=f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_after_three_consecutive_spaces(input_file, output_file):\n",
    "    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "        for line in infile:\n",
    "            # Find the index of three consecutive spaces\n",
    "            index = line.find('   ')\n",
    "            \n",
    "            # If three consecutive spaces are found, truncate the line\n",
    "            if index != -1:\n",
    "                truncated_line = line[:index + 3] + '\\n'\n",
    "            else:\n",
    "                truncated_line = line\n",
    "            \n",
    "            # Write the truncated line to the output file\n",
    "            outfile.write(truncated_line)\n",
    "\n",
    "def encapsulate_lowercase(file_path, output_file_path):\n",
    "    with open(file_path, 'r') as infile, open(output_file_path, 'w') as outfile:\n",
    "        for line in infile:\n",
    "            modified_line = ''.join([f\"'{char}'\" if char.islower() else char for char in line])\n",
    "            outfile.write(modified_line)\n",
    "\n",
    "\n",
    "input_file_path = 'grammar_start.txt'\n",
    "middle_path = 'grammar_middle.txt'\n",
    "output_file_path = 'grammar.txt'\n",
    "\n",
    "truncate_after_three_consecutive_spaces(input_file_path, middle_path)\n",
    "\n",
    "encapsulate_lowercase(middle_path, output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the grammar to NLTK grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('grammar.txt', 'r') as f:\n",
    "    grammar = f.read()\n",
    "\n",
    "grammar = CFG.fromstring(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Grammar with 52393 productions>"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -> 'a' 'a'\n"
     ]
    }
   ],
   "source": [
    "productions = grammar.productions()\n",
    "for production in productions:\n",
    "    if production.lhs() == nltk.grammar.Nonterminal('1'):\n",
    "        print(production)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = nltk.ChartParser(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 0\n"
     ]
    }
   ],
   "source": [
    "def check_sentence(sentence):\n",
    "    try:\n",
    "        next(parser.parse(sentence))\n",
    "        return 0\n",
    "    except StopIteration:\n",
    "        return 1\n",
    "    except ValueError:\n",
    "        return 1\n",
    "\n",
    "# Example usage\n",
    "sentence_to_check = \"aaaaabba\"\n",
    "result = check_sentence(sentence_to_check)\n",
    "\n",
    "print(\"Result:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latency</th>\n",
       "      <th>CategoriesControllerGetcategory</th>\n",
       "      <th>ItemsControllerFindfeaturesitemrandom</th>\n",
       "      <th>ItemsControllerFinditemrandom</th>\n",
       "      <th>ItemsControllerFinditemsrandombyidproduct</th>\n",
       "      <th>ProductsControllerFindproduct</th>\n",
       "      <th>ProductsControllerFindproductrandom</th>\n",
       "      <th>GatewayGet</th>\n",
       "      <th>anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>384</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>431</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>372</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>404</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>362</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Latency  CategoriesControllerGetcategory  \\\n",
       "0      384                                5   \n",
       "1      431                                3   \n",
       "2      372                                4   \n",
       "3      404                                3   \n",
       "4      362                                4   \n",
       "\n",
       "   ItemsControllerFindfeaturesitemrandom  ItemsControllerFinditemrandom  \\\n",
       "0                                      3                              4   \n",
       "1                                      2                              4   \n",
       "2                                      3                              3   \n",
       "3                                      3                              4   \n",
       "4                                      3                              4   \n",
       "\n",
       "   ItemsControllerFinditemsrandombyidproduct  ProductsControllerFindproduct  \\\n",
       "0                                         43                              3   \n",
       "1                                         50                              3   \n",
       "2                                         52                              3   \n",
       "3                                         60                              3   \n",
       "4                                         53                              3   \n",
       "\n",
       "   ProductsControllerFindproductrandom  GatewayGet  anomaly  \n",
       "0                                    3         130        0  \n",
       "1                                    3         112        0  \n",
       "2                                    3         114        0  \n",
       "3                                    4         135        0  \n",
       "4                                    3         123        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(os.path.join(\"data\",\"eshopper\",\"200.csv\"))\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dange\\anaconda3\\envs\\grammar\\lib\\site-packages\\pyts\\preprocessing\\discretizer.py:168: UserWarning: Some quantiles are equal. The number of bins will be smaller for sample [0 1 2 3 4 5 6]. Consider decreasing the number of bins or removing these samples.\n",
      "  warn(\"Some quantiles are equal. The number of bins will \"\n"
     ]
    }
   ],
   "source": [
    "from pyts.approximation import SymbolicAggregateApproximation\n",
    "\n",
    "sax = SymbolicAggregateApproximation(n_bins=10)\n",
    "data_sax = sax.fit_transform(test.drop(['anomaly'], axis=1).T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame(data_sax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['string'] =  [''.join(map(str, row)) for row in data_sax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['result'] = d.apply(lambda x: check_sentence(x['string']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['anomaly'] = test['anomaly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.loc[d['anomaly'] == 2, 'anomaly'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9215707853009418\n",
      "Precision: 0.7565350308612117\n",
      "Recall: 0.8963572591183145\n",
      "F1 Score: 0.8205321917233275\n",
      "Confusion Matrix:\n",
      "[[161878  12583]\n",
      " [  4521  39100]]\n",
      "ROC AUC Score: 0.9121161284844185\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Assuming y_pred and y_test are your predicted and true labels (binary 0 or 1)\n",
    "y_pred = d['result']\n",
    "y_test = d['anomaly']\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# ROC AUC Score\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(\"ROC AUC Score:\", roc_auc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grammar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
